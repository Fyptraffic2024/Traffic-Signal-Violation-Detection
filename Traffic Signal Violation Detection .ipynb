{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d906dc6",
   "metadata": {},
   "source": [
    "### Install Require Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/abewley/sort\n",
    "%cd /content/sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_matplotlib_backend(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            if \"matplotlib.use('TkAgg')\" in line or 'matplotlib.use(\"TkAgg\")' in line:\n",
    "                line = line.replace(\"matplotlib.use('TkAgg')\", \"matplotlib.use('Agg')\").replace('matplotlib.use(\"TkAgg\")', \"matplotlib.use('Agg')\")\n",
    "            file.write(line)\n",
    "\n",
    "# Example usage:\n",
    "update_matplotlib_backend('sort.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install filterpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f59806",
   "metadata": {},
   "source": [
    "### Red Violation and Number plate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from ultralytics import YOLO  # Ensure you have YOLOv8 installed\n",
    "from sort import Sort   # Make sure you have the SORT tracker installed\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "# ---------- Helper Functions ----------\n",
    "def load_histogram(file_path):\n",
    "    \"\"\"Load a histogram from a pickle file.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        histogram = pickle.load(file)\n",
    "    return histogram\n",
    "## Below Function is for Simple Histogram\n",
    "# def calculate_histogram(image, bbox):\n",
    "#     \"\"\"Calculate and normalize the histogram for a region in the image.\"\"\"\n",
    "#     height, width, _ = image.shape\n",
    "#     x_center, y_center, box_width, box_height = bbox\n",
    "\n",
    "#     x_min = int((x_center - box_width / 2) * width)\n",
    "#     x_max = int((x_center + box_width / 2) * width)\n",
    "#     y_min = int((y_center - box_height / 2) * height)\n",
    "#     y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "#     roi = image[y_min:y_max, x_min:x_max]\n",
    "#     histogram = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "#     histogram = cv2.normalize(histogram, histogram).flatten()\n",
    "#     return histogram\n",
    "# Below Function is for Gray Scale Histogram\n",
    "def calculate_histogram(image, bbox):\n",
    "    \"\"\"Calculate and normalize the grayscale histogram for a region in the image.\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    x_center, y_center, box_width, box_height = bbox\n",
    "\n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    # Crop the region of interest\n",
    "    roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute histogram\n",
    "    histogram = cv2.calcHist([gray_roi], [0], None, [256], [0, 256])\n",
    "    histogram = cv2.normalize(histogram, histogram).flatten()\n",
    "    return histogram\n",
    "\n",
    "def compare_histograms(frame_histogram, reference_histogram):\n",
    "    \"\"\"\n",
    "    Compare the frame histogram with the reference histogram using correlation.\n",
    "    Returns a similarity score.\n",
    "    \"\"\"\n",
    "\n",
    "    score = cv2.compareHist(frame_histogram, reference_histogram, cv2.HISTCMP_CORREL)\n",
    "    return score\n",
    "\n",
    "def draw_arrow(frame, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Draw a large, filled downward arrow above the detected object.\n",
    "    \"\"\"\n",
    "    center_x = (x1 + x2) // 2\n",
    "    top_y = y1 - 150  # position above the bounding box\n",
    "\n",
    "    arrow_width = 50\n",
    "    arrow_height = 100\n",
    "    shaft_width = 20\n",
    "\n",
    "    arrow_tip = (center_x, y1)\n",
    "    left_corner = (center_x - arrow_width, top_y + arrow_height)\n",
    "    right_corner = (center_x + arrow_width, top_y + arrow_height)\n",
    "\n",
    "    shaft_top_left = (center_x - shaft_width, top_y)\n",
    "    shaft_top_right = (center_x + shaft_width, top_y)\n",
    "    shaft_bottom_left = (center_x - shaft_width, top_y + arrow_height)\n",
    "    shaft_bottom_right = (center_x + shaft_width, top_y + arrow_height)\n",
    "\n",
    "    arrow_head = np.array([arrow_tip, left_corner, right_corner], np.int32)\n",
    "    arrow_shaft = np.array([shaft_top_left, shaft_bottom_left, shaft_bottom_right, shaft_top_right], np.int32)\n",
    "\n",
    "    color = (0, 0, 255)  # red arrow\n",
    "    cv2.fillPoly(frame, [arrow_head], color)\n",
    "    cv2.fillPoly(frame, [arrow_shaft], color)\n",
    "\n",
    "def is_within_path(car_center_x, car_center_y, path_bbox, frame_shape):\n",
    "    \"\"\"\n",
    "    Check if the car's center lies within the specified path region.\n",
    "    \"\"\"\n",
    "    height, width, _ = frame_shape\n",
    "    x_center, y_center, box_width, box_height = path_bbox\n",
    "\n",
    "    x_min = int((x_center - box_width / 2) * width)\n",
    "    x_max = int((x_center + box_width / 2) * width)\n",
    "    y_min = int((y_center - box_height / 2) * height)\n",
    "    y_max = int((y_center + box_height / 2) * height)\n",
    "\n",
    "    return x_min <= car_center_x <= x_max and y_min <= car_center_y <= y_max\n",
    "\n",
    "def point_side(point, line_start, line_end):\n",
    "    \"\"\"\n",
    "    Compute the cross product of vectors (line_start -> point) and (line_start -> line_end).\n",
    "    A positive value indicates that 'point' is on one side of the line,\n",
    "    and a negative value indicates the opposite side.\n",
    "    \"\"\"\n",
    "    return (point[0] - line_start[0]) * (line_end[1] - line_start[1]) - \\\n",
    "           (point[1] - line_start[1]) * (line_end[0] - line_start[0])\n",
    "\n",
    "# ---------- Integrated Processing Function Using SORT ----------\n",
    "def save_tracking_info_to_csv(processed_frame, track_id, x1, y1, x2, y2, csv_writer):\n",
    "    \"\"\"\n",
    "    Save the tracking information to a CSV file when a violation is detected.\n",
    "    \"\"\"\n",
    "    csv_writer.writerow([processed_frame, track_id, int(x1), int(y1), int(x2), int(y2)])\n",
    "\n",
    "def process_video_with_sort(input_video_path, reference_histogram_file, bbox, path_bbox, output_video_path,\n",
    "                            upper_line_start, upper_line_end, lower_line_start, lower_line_end,\n",
    "                            threshold, save_frames=False, temp_frame_folder=None, csv_output_path=None):\n",
    "    \"\"\"\n",
    "    Process the video with SORT tracking.\n",
    "      - Compute the grayscale histogram in a specified region.\n",
    "      - Compare with a reference histogram.\n",
    "      - If the similarity score exceeds the threshold (signal is Red),\n",
    "        run YOLO detection, update the SORT tracker, and process detections.\n",
    "      - Only write (crop) the frame to the output video when the signal is Red.\n",
    "      - Save tracking info (Frame, ID, x1, y1, x2, y2) to CSV according to the cut video.\n",
    "    \"\"\"\n",
    "    reference_histogram = load_histogram(reference_histogram_file)\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    tracker = Sort()\n",
    "    video_cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    csv_file = None\n",
    "    csv_writer = None\n",
    "    if csv_output_path:\n",
    "        csv_file = open(csv_output_path, mode='w', newline='')\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['Frame', 'ID', 'x1', 'y1', 'x2', 'y2'])  # CSV header\n",
    "\n",
    "    track_states = {}\n",
    "    frame_count = 0  # Frame index in the original video\n",
    "    processed_frame_count = 0  # Frame index in the cut video\n",
    "\n",
    "    while video_cap.isOpened():\n",
    "        ret, frame = video_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Draw custom lines\n",
    "        #cv2.line(frame, upper_line_start, upper_line_end, (0, 255, 255), 2)\n",
    "        #cv2.line(frame, lower_line_start, lower_line_end, (255, 0, 0), 2)\n",
    "\n",
    "        # Compute the grayscale histogram\n",
    "        frame_histogram = calculate_histogram(frame, bbox)\n",
    "        score = compare_histograms(frame_histogram, reference_histogram)\n",
    "        print(score)\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        x_center, y_center, box_width, box_height = bbox\n",
    "        x_min = int((x_center - box_width / 2) * w)\n",
    "        x_max = int((x_center + box_width / 2) * w)\n",
    "        y_min = int((y_center - box_height / 2) * h)\n",
    "        y_max = int((y_center + box_height / 2) * h)\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Score: {score:.2f}\", (x_min, y_max + 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        if score > threshold:\n",
    "            results = model(frame)\n",
    "            detections_list = []\n",
    "\n",
    "            for box in results[0].boxes.data.cpu().numpy():\n",
    "                x1, y1, x2, y2, conf, cls = box[:6]\n",
    "                if int(cls) != 2:\n",
    "                    continue\n",
    "                detections_list.append([x1, y1, x2, y2, conf])\n",
    "\n",
    "            detections = np.array(detections_list) if len(detections_list) > 0 else np.empty((0, 5))\n",
    "            tracked_objects = tracker.update(detections)\n",
    "\n",
    "            for d in tracked_objects:\n",
    "                x1, y1, x2, y2, track_id = d\n",
    "                track_id = int(track_id)\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "\n",
    "                if not is_within_path(center_x, center_y, path_bbox, frame.shape):\n",
    "                    continue\n",
    "\n",
    "                if track_id not in track_states:\n",
    "                    if point_side((center_x, center_y), lower_line_start, lower_line_end) > 0:\n",
    "                        track_states[track_id] = {\"entered\": True, \"violated\": False}\n",
    "                else:\n",
    "                    if track_states[track_id][\"entered\"] and point_side((center_x, center_y), upper_line_start, upper_line_end) > 0:\n",
    "                        track_states[track_id][\"violated\"] = True\n",
    "\n",
    "                if track_states.get(track_id, {}).get(\"violated\", True):\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "                    draw_arrow(frame, int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "                    if csv_writer:\n",
    "                        save_tracking_info_to_csv(processed_frame_count, track_id, x1, y1, x2, y2, csv_writer)\n",
    "\n",
    "            video_writer.write(frame)\n",
    "            processed_frame_count += 1  # Increment only when a frame is written to the output\n",
    "\n",
    "        frame_count += 1  # Always increment for original video frame count\n",
    "\n",
    "    video_cap.release()\n",
    "    video_writer.release()\n",
    "    if csv_file:\n",
    "        csv_file.close()\n",
    "def draw_text_with_background(img, text, x, y, font_scale=0.6, text_color=(0, 0, 255), bg_color=(255, 255, 255), thickness=1):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, (x, y - text_h - 4), (x + text_w + 4, y), bg_color, -1)\n",
    "    cv2.putText(img, text, (x + 2, y - 2), font, font_scale, text_color, thickness, cv2.LINE_AA)\n",
    "def call_plate_api(image_path, api_key, retries=4, delay=6):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            with open(image_path, 'rb') as fp:\n",
    "                response = requests.post(\n",
    "                    'https://api.platerecognizer.com/v1/plate-reader/',\n",
    "                    files={'upload': fp},\n",
    "                    headers={'Authorization': f'Token {api_key}'}\n",
    "                )\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
    "            print(f\"Error: {e}. Retrying {attempt + 1}/{retries}...\")\n",
    "            time.sleep(delay)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}. Skipping this object.\")\n",
    "            return None\n",
    "    print(\"Max retries reached. Skipping this object.\")\n",
    "    return None\n",
    "def plate_detection(input_video, output_video, api_key, tracking_data,retry_interval=26):\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "      # Cache for API results and retry tracking\n",
    "    plate_cache = {}\n",
    "    retry_tracker = defaultdict(lambda: -retry_interval)  # Last frame when API was called for each ID\n",
    "\n",
    "      # Add progress bar\n",
    "    for frame_idx in tqdm(range(frame_count), desc=\"Processing frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "          # Display progress output for the current frame\n",
    "        print(f\"Processing frame {frame_idx}/{frame_count - 1}\")\n",
    "          # Get data for the current frame from tracking data\n",
    "        frame_data = tracking_data[tracking_data['Frame'] == frame_idx]\n",
    "        for _, row in frame_data.iterrows():\n",
    "            obj_id = row['ID']\n",
    "            x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])\n",
    "              # Check if plate number is already cached or if it's time to retry\n",
    "            if obj_id not in plate_cache or (plate_cache[obj_id] == 'N/A' and frame_idx - retry_tracker[obj_id] >= retry_interval):\n",
    "                # Crop the object region\n",
    "                cropped = frame[y1:y2, x1:x2]\n",
    "                cv2.imwrite('temp.jpg', cropped)\n",
    "                # Call the API with retries\n",
    "                api_response = call_plate_api('temp.jpg', api_key)\n",
    "                if api_response and 'results' in api_response and api_response['results']:\n",
    "                    plate_number = api_response['results'][0]['plate']\n",
    "                else:\n",
    "                    plate_number = 'N/A'\n",
    "                  # Update cache and retry tracker\n",
    "                  plate_cache[obj_id] = plate_number\n",
    "                retry_tracker[obj_id] = frame_idx\n",
    "            # Visualize the bounding box and plate number\n",
    "            plate_number = plate_cache[obj_id]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            draw_text_with_background(frame, plate_number, x1, y1 - 10, font_scale=2, text_color=(0, 0, 255), bg_color=(255, 255, 255), thickness=2)\n",
    "        out.write(frame)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Video processing completed!\")\n",
    "\n",
    "#---------------------------------Input Canal----------------------------------------\n",
    "input_video_path = '/content/drive/MyDrive/Input_Data/vid1_Canal.mp4'\n",
    "reference_histogram_file = '/content/drive/MyDrive/Histogram/Red_colored_hist_canal.pkl'\n",
    "bbox =(0.246313, 0.375587, 0.041298, 0.154430)  # Normalized coordinates\n",
    "path_bbox = (0.720047, 0.827044, 0.559906, 0.345912)  # New specified path coordinate\n",
    "lower_line_start = (696,1069)\n",
    "lower_line_end   = (1916,1064)\n",
    "upper_line_start = (657,953)\n",
    "upper_line_end   = (1920,959)\n",
    "output_video_path = '/content/drive/MyDrive/Resulted_violation/output_video_canal.mp4'  # Output video path\n",
    "# Process the video:\n",
    "process_video_with_sort(input_video_path,\n",
    "                        reference_histogram_file,\n",
    "                        bbox,path_bbox,\n",
    "                        output_video_path,\n",
    "                        upper_line_start,upper_line_end,\n",
    "                        lower_line_start,lower_line_end,\n",
    "                        threshold=0.6,\n",
    "                        csv_output_path=\"/content/drive/MyDrive/Resulted_violation/tracking_info_canal_1.csv\")\n",
    "#----------------------------------------Plate Detection--------------------------------------\n",
    "api_key = 'df9ea40d34e80d6149f57d04d8b1328d61920916'\n",
    "input_plate_video = '/content/drive/MyDrive/Resulted_violation/output_video_canal.mp4'\n",
    "tracking_data=pd.read_csv('/content/drive/MyDrive/Resulted_violation/tracking_info_canal_1.csv')\n",
    "output_plate_video = '/content/drive/MyDrive/Resulted_violation/canal_plate.mp4'  #Output plate video path\n",
    "plate_detection(input_plate_video,output_plate_video,api_key,tracking_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
